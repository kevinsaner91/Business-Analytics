---
title: "Assignment Data Analysis"
author: "Kevin Saner, Phillip Gachnang, Raphael Denz"
date: "18. 3. 2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Starting situation
The case is adapted from Sharpe, N.R., Ali, A., Potter, M.E. (2001): A Casebook for Business Statistics, Wiley, New York, p 13-20. The case (Sharpe-etal-NPD-Case-A-1-3.pdf), the questionnaire of the survey (NPD-Questionnaire.pdf) and the data of the case (npd.sav) are on moodle. The data is stored as an SPSS-file. Read the data using the data import of RStudio and carry out the tasks below using R.

## To-Do
Carry out the following tasks. Comment on each of the results in a few words! Work in groups of 3 members. Establish a report. Write the full names of all members of the group on the top of the first page of the report. Upload the report as a pdf to moodle: Only one person per group must upload the pdf.

## Prerequisites
```{r, message=FALSE,warning=FALSE}
library(DescTools) # for CramerV() function
library(haven) # to read SPSS files
library(labelled) # to deal with variable and value labels
library(knitr) # to get the kable() function for nice tables
library(gplots) # to get the plotmeans() function
library(ggplot2) # for grouped boxplot
```

# 1 Data Preparation

## 1.1 Read the data

```{r message=FALSE, warning=FALSE, include=FALSE}
rm(list = ls()) # clear workspace, use if needed
dataset = read_sav("npd.sav")

```

## 1.2 Check the dimension and the variables

*Check the dimensions of the data set. What are the names. Is the data labelled?*

```{r}
a<- dim(dataset)
a

```

The above output shows that the dataset contains `r a[1]` observations and `r a[2]` variables.

```{r}
names(dataset)
```
The above command delivers the names of the columns in the data set. It can be seen that the names of the columns match the questions of the questionnaire. The data set contains no labels. Some of the data in the data set is stored as free text such as the product category (A1). Most of data, however, is stored as numerical data where it only becomes clear when looking at the questionnaire whether the data refers to qualitative or quantitative data. The below example marks an exception: 

```{r}
# example of different encoding styles
head(dataset$A2)
head(dataset$B1)
```
Although, both questions A2 and B1 refer to a "Yes"- or "No"-question, the way the answers are stored look different. This due to a inconsistent encoding style.

## 1.3 Response

*Calculate the unit response rate.*

```{r}
# store gross sample size
gross_sample_size <- 592
# keep only rows that indicated completeness
dataset <- subset(dataset,dataset$COMPLETE!="")
100 /gross_sample_size * nrow(dataset)

```
To calculate the unit response rate only data is considered that is complete. Incomplete data is identified using the column "Complete". This way a unit reponse rate of 41.55% is calculated, meaning that less than half the companies that were asked completed the questionnaire.

## 1.4 Measurement Levels and Missingness

*Check the measurement levels and missigness of sections C & D.*

### 1.4a Measurement Levels

The measurement levels of the variables in section C & D are follows:

* C1 - C4 are ratios
* C 5 -7 are ordinally scaled variable
* C8, C9 & D1 are ratios
* D2 is a nominal variable
* D3 is a nominal variable that uses one-hot encoding
* D4 - D8 are ratios
* D9IncYes1 is a nominal variable
* D9* is dependent on D9IncYes1 and also uses one-hot encoding

To make the data better readable it is useful to label the ordinal and nominal variables. 
Variables C5 - C7 follow a 7-level Likert-Scale, therefore the labels will be:  

1 = Strongly Disagree  
2 = Disagree  
3 = Somewhat Disagree  
4 = Neither Agree or Disagree  
5 = Somewhat Agree  
6 = Agree  
7 = Strongly Agree



```{r}
# transform the variables to factor and add labels
to_7_level_likert <- function(x){
x <- factor(x,
                     levels = c(1,2,3,4,5,6,7), 
                     labels = c("Strongly Disagree",
                                "Disagree",
                                "Somewhat Disagree",
                                "Neither Agree or Disagree",
                                "Somewhat Agree",
                                "Agree",
                                "Strongly Agree"),
                     ordered = TRUE)
}
dataset$C5 <- to_7_level_likert(dataset$C5)
dataset$C6 <- to_7_level_likert(dataset$C6)
dataset$C7 <- to_7_level_likert(dataset$C7)
# example of the newly introduced factors
levels(dataset$C5)

```
The example shows the levels of the transformed variable C5.

D2 and D9IncYes1 are nominal variables with two levels each. The variables are also transformed to factors and labels are added.
```{r}
dataset$D2 <- factor(dataset$D2,
                     levels = c(1,2),
                     labels = c("Privately held","Publicly Traded"),
                     ordered = FALSE)
dataset$D9IncYes1 <- factor(dataset$D9IncYes1,
                            levels = c(0,1),
                            labels = c("No","Yes"),
                            ordered = FALSE)
summary(dataset$D2)
summary(dataset$D9IncYes1)

```
The output shows the count of occurrences per label. 

### 1.4b Missingness

*Check data for missing values in sections C and D.*

```{r}
#create a subset that only contains sections C and D
dataset_c_d <- dataset[,grep("C1",colnames(dataset)):grep("D9EGov",colnames(dataset))]
out <- table(sapply(dataset_c_d, is.na))
out

```
There are `r out[2]`  missing values in the data set. The values are distributed as follows among the variables:

```{r}
data.frame(colSums(is.na(dataset_c_d)))
```
## 1.5 Missingness of D9IncYes1

*Create a contingency table between is.na(D4) and is.na(D9IncYes1)*

```{r}
# contingency table
table(is.na(dataset$D4),is.na(dataset$D9IncYes1))

```
The result of the contigency tables shows that, 223 have answered both questions, 9 have answered neither D4 nor D9IncYes1, 10 have answered D4 but not D9IncYes1 and 4 have answered D9IncYes1 but not D4. To sum, there are only 23 companies that did not answer one of the questions, which relates to roughly 10% of responders.

*Create a grouped boxplot to compare responders and non-responders.*

```{r}
#make a subset with only the variables of interest
dataset_D4_D9IncYes1 <- dataset[,c("D4","D9IncYes1")]
#keep only rows where the company size is meaningful
dataset_D4_D9IncYes1<- subset(dataset_D4_D9IncYes1,!is.na(dataset$D4))
#if D9IncYes1 is !NA, it counts as reponder
dataset_D4_D9IncYes1$D9IncYes1 <- factor(dataset_D4_D9IncYes1$D9IncYes1,
                            levels = c("Yes","No"),
                            labels = c("Responder","Responder"),
                            ordered = FALSE)
# outliers are hidden in the boxplot
ggplot(dataset_D4_D9IncYes1, aes(x=D9IncYes1,y=D4)) + geom_boxplot(outlier.colour = NA) +  coord_cartesian(ylim = c(0, 60)) + xlab("Responder/Non-Responder") + ylab("Number of employees")

```
The median of the NA-group is close to 20, whereas the median of the responders is under 10, which indicates 
a size difference of the companies when looking at the employees. Additionally, a wilcoxon test is done to test this hypothesis:
```{r}
# test for a statistically significant difference between responder and non-responder
wilcox.test(dataset$D4[which(is.na(dataset$D9IncYes1))],dataset$D4[which(!is.na(dataset$D9IncYes1))])
```
The Wicoxon-Test we can reject the null hypothesis, which means that companies that did not respond to D9IncYes1 have more employees.

# 2 Analysis

## 2.1 Proportion of Programme 

*Calculate the proportion and 95% confidence interval for incubator participants.*

```{r}
#only non-NA values are used to calculate the total
D9IncAll <- length(subset(dataset$D9IncYes1,!is.na(dataset$D9IncYes1)))
D9IncYes <- length(subset(dataset$D9IncYes1,dataset$D9IncYes1=="Yes"))

D9IncAll
D9IncYes 

prop.test(D9IncYes,D9IncAll) 
```
The output shows that there are 227 companies that responded to question D9IncYes1, of which 68 answered "yes - they did participate in an incubator programme". This results in a proportion of approximately 30% with a 95% confidence interval between 24,2% and 36,4%. In other words, we are 95% confident that the true proportion of survey participants that participated in an incubator programme lies between 24,2% and 36,4%.  


## 2.2 Satisfaction with product development process
*Analyse the satisfaction with the product development process (C5) using a barchart.*
```{r}
barplot(table(dataset$C5), main="Barchart of Satisfaction", xlab="Satisfaction", ylab="Frequency")

```
```{r echo=FALSE}
#get the max and min values of labels to refer within the text below
a = min(subset(dataset$C5,!is.na(dataset$C5)))
b = max(subset(dataset$C5,!is.na(dataset$C5)))
```
The barchart shows in this case a histogram, the frequency distribution of product development process satisfaction of all participants. The plot depicts the comparison of the satisfaction ratio from `r names(table(dataset$C5)[a])` to `r names(table(dataset$C5)[b])` in `r nlevels(dataset$C5)` levels. The frequency distribution leans towards `r names(table(dataset$C5)[b])`. The highest frequency with `r table(dataset$C5)[b]` participants are `r names(table(dataset$C5)[b])` while the lowest frequency with only `r table(dataset$C5)[a]` participants `r names(table(dataset$C5)[a])` with the satisfaction of their product development process. We can conclude here, that most are at least satisfied by their product development process.

## 2.3 Association of incubator participation and satisfaction with the product development process
```{r}
con = table(dataset$C5, dataset$D9IncYes1)
con
mosaicplot(con, shade = TRUE, las=3)
chiresult <- chisq.test(dataset$C5, dataset$D9IncYes1)
chiresult
cV <- CramerV(con)
cV

```
As p-value of the chi-squered test of `r chiresult$p.value` is greater than the 0.05 significance level, we do not reject the null hypothesis that the satisfaction of the product development process is independent on the incubation program. According to the documentation, a Cramer's V in the range of [0, 0.3] is considered as weak and the result of a value of `r cV` is therefore considered as a weak. To conclude the two results, even if there is an dependency of the satisfaction of the product development process with the incubation program, this dependency seems to be weak.

## 2.4 Number of R+D personnel

```{r, message=FALSE,warning=FALSE}

## Histograms and boxplots

hist(dataset$D5)
hist(log(dataset$D5)+1)
boxplot(dataset$D5)
boxplot(log(dataset$D5)+1)

# Quartile calculation for Bowley Skeweness 

# ((Q3 - Q2) - (Q2 - Q1))/(Q3 - Q1)
# Skewness = 0 means that the curve is symmetrical
# Skewness > 0 means the curve is positively skewed
# Skewness < 0 means the curve is negatively skewed

Q1 <- quantile(dataset$D5, prob=c(.25), na.rm=TRUE) 
Q2 <- quantile(dataset$D5, prob=c(.5), na.rm=TRUE)
Q3 <- quantile(dataset$D5, prob=c(.75), na.rm=TRUE)

bowley <- ((Q3 - Q2) - (Q2 - Q1))/(Q3 - Q1)
bowley

```
Using the histogram and boxplot for the distribution of R&D personnel, we can see in the normal graphics that the values are extremely squished in the direction of 0 and far distant outliers. Using log ("log(D5+1)"), we can improve the graphics with establishing a normal distribution. According to the new histogram and boxplot, we can identify that most values are almost centered around 2. Which means most survey participants have two R&D personnel.

To further analyse the R&D personnel distribution, the Bowley Skeweness is calculated using the quartiles: 

[(Q3 - Q2) - (Q2 - Q1)] / (Q3 - Q1)

The result of the Bowley Skeweness tells us if the curve is symmetrical (Skeweness = 0), positively skewed (Skeweness > 0) or negatively skewed (Skeweness < 0). In this case, the skeweness is above 0, which indicates that the curve for the distribution of R&D personel is positively skewed. 

## 2.5 R+D personnel vs participation

```{r, message=FALSE,warning=FALSE}

test = aggregate(dataset$D5, by=list(dataset$D9IncYes1), FUN=qqnorm, na.action = na.omit)
boxplot(test$x[1,]$y, test$x[2,]$y, names = c("No", "Yes"))

factorvar <- factor(c(dataset$D9IncYes1))
plot(x=factorvar, y=dataset$D5)
plot(x=factorvar, y=log(dataset$D5)+1)

boxplot(log(test$x[1,]$y)+1, log(test$x[2,]$y)+1, names = c("No", "Yes"))

# Shapiro-Test
# P-value above 0.05 or 5% means it is normally distributed and the Null hypothesis is not rejected
# When H0 is not rejected, we can use the t-test.
# WHen H0 is rejected (no normal distribution), we wan use the Wilcox-test

shapiro.test(dataset$D5[which(dataset$D9IncYes1==c("No","Yes"))])

# T-Test
# If the p-value of the t-test is less than 0.05 or 5% (significance level), we can reject the Null hypothesis - both populations are not significant differently
# If the p-value of the t-test is higher than 0.05 or 5% (significance level), we accept H0 - both populations are significant differently

t.test(x=dataset$D5, y=dataset$D9IncYes1)
t.test(test$x[1,]$y, test$x[2,]$y, alternative = "two.sided") # H0 auch rejected

# Wilcox-Test
# The Wilcox-Test, also called Wilcoxon-Mann-Whitney-Test, U-Test or Wilcoxon rank-sum test, is used, when the requirements for a t-test for independent samples are not fulfilled. The Wilcox-Test can be used, when there is no normal distribution.
# If the p-value of the Wilcox-Test is less than 0.05 or 5% (significance level), we can reject the Null hypothesis - both populations are not significant differently
# If the p-value of the Wilcox-Test is higher than 0.05 or 5% (significance level), we accept H0 - both populations are significant differently

wilcox.test(test$x[1,]$y, test$x[2,]$y, alernative="two-sided")



```

## TODO - Boxplot und normal plor + log transformed numbers erklären

The t-test (which should not be used, according to the Shapiro-Test) and Wilcox-test assumes that the R&D personel for participants and non-participants are not significantly different. We can reject in both tests this Null hypothesis, because both tests give a lower p-value than the significance level of 5%. Therefore, the R&D personnel of participants and non-participants are significant different. 


